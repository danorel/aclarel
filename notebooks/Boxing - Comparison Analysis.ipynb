{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca45a75-f165-4ea3-bc90-82975e6a1ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danorel/Workspace/Education/University/KMA/Research/aclarel\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39deedfb-bba0-4411-ba29-682770bd9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import environments.atari_games.boxing.environment as boxing\n",
    "import environments.atari_games.boxing.experiments as experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578746b-32c2-4d99-97c1-ddb34ac23df5",
   "metadata": {},
   "source": [
    "## Curriculum Learning: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe9e13-c218-4b3b-a556-4cadca967a73",
   "metadata": {},
   "source": [
    "### Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da28ed2-c431-4eaf-8c1b-06379ed1223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_frame_from_agent(agent):\n",
    "    df = pd.DataFrame(agent.measurements)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177b7c8-d10a-4258-976e-b39bcf5e148b",
   "metadata": {},
   "source": [
    "## Reinforcement Learning: Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e36bc6a-1ea4-4cec-b410-2a53cee6dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = pathlib.Path(\"datasets\") / \"atari_games\" / \"boxing\"\n",
    "DATASETS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c33c5a-95bc-4c06-9ae4-a237d2a2d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['agent_name', 'evaluation', 'curriculum_name', 'aar', 'ses', 'learning_stability', 'mean_reward', 'std_reward', 'total_reward', 'success_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6e92a-49c0-4c9f-9ca9-2dfad2290c98",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381359f6-ce78-48fc-b4b4-450891ecf863",
   "metadata": {},
   "source": [
    "#### Curriculum parameter: frame skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c9f1e-b0ac-4375-878f-4a6eff425452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n",
      "Device: cpu\n",
      "Autocast gradients: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 'dqn' via CL method 'one-pass' has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                   | 0/21 [00:00<?, ?it/s]\u001b[A/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/Users/danorel/Workspace/Education/University/KMA/Research/aclarel/environments/atari_games/boxing/rl_methods/__init__.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.measurements = pd.concat([self.measurements, measurement], ignore_index=True)\n",
      "\n",
      "  5%|████▉                                                                                                   | 1/21 [05:15<1:45:01, 315.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 0:\n",
      "\tTraining:\n",
      " \t\tFrameskip: 1\n",
      " \t\tStability: 10.707\n",
      "\tEvalution:\n",
      " \t\tAAR: -0.002\n",
      " \t\tSES: 1.0\n",
      " \t\tMean Reward: -16.0\n",
      " \t\tStd Reward: 3.286\n"
     ]
    }
   ],
   "source": [
    "from environments.atari_games.boxing.rl_methods.dqn import DQNAgent\n",
    "\n",
    "dqn_agent = functools.partial(experiments.get_agent, agent_name='dqn')\n",
    "dqn_path = DATASETS_DIR / 'dqn.csv'\n",
    "\n",
    "agents = [\n",
    "    dqn_agent(curriculum_name='one-pass'),\n",
    "    dqn_agent(curriculum_name='root-p'),\n",
    "    dqn_agent(curriculum_name='hard'),\n",
    "    dqn_agent(curriculum_name='linear'),\n",
    "    dqn_agent(curriculum_name='logarithmic'),\n",
    "    dqn_agent(curriculum_name='logistic'),\n",
    "    dqn_agent(curriculum_name='mixture'),\n",
    "    dqn_agent(curriculum_name='polynomial'),\n",
    "    dqn_agent(curriculum_name='anti-curriculum')\n",
    "]\n",
    "\n",
    "file_exists_and_not_empty = os.path.exists(dqn_path) and os.path.getsize(dqn_path) > 0\n",
    "\n",
    "with open(dqn_path, 'a') as f:\n",
    "    if not file_exists_and_not_empty:\n",
    "        f.write(f\"{','.join(COLUMNS)}\\n\")\n",
    "        f.flush()\n",
    "    for agent in tqdm(agents):\n",
    "        print(f\"Training of '{agent.metadata['agent_name']}' via CL method '{agent.metadata['curriculum_name']}' has started\")\n",
    "        curriculum = experiments.get_curriculum(agent)\n",
    "        boxing.train_evaluate(agent, curriculum)\n",
    "        agent_df = data_frame_from_agent(agent)\n",
    "        if f.tell() == 0:\n",
    "            agent_df.to_csv(f, index=False)\n",
    "        else:\n",
    "            agent_df.to_csv(f, header=False, index=False)\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab04375-6ae4-4a04-a7ce-095a0e7c8d4a",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a7c7c-63be-44ec-ac45-8562ec58e8ba",
   "metadata": {},
   "source": [
    "#### Curriculum parameter: frame skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bae37-cc5f-4a67-90e4-0985d5940885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from environments.atari_games.boxing.rl_methods.ppo import PPOAgent\n",
    "\n",
    "ppo_agent = functools.partial(experiments.get_agent, agent_name='ppo')\n",
    "ppo_path = DATASETS_DIR / 'ppo.csv'\n",
    "\n",
    "agents = [\n",
    "    ppo_agent(curriculum_name='baseline'),\n",
    "    ppo_agent(curriculum_name='transfer-learning'),\n",
    "    ppo_agent(curriculum_name='teacher-learning'),\n",
    "    ppo_agent(curriculum_name='one-pass'),\n",
    "    ppo_agent(curriculum_name='root-p'),\n",
    "    ppo_agent(curriculum_name='hard'),\n",
    "    ppo_agent(curriculum_name='linear'),\n",
    "    ppo_agent(curriculum_name='logarithmic'),\n",
    "    ppo_agent(curriculum_name='logistic'),\n",
    "    ppo_agent(curriculum_name='mixture'),\n",
    "    ppo_agent(curriculum_name='polynomial'),\n",
    "    ppo_agent(curriculum_name='anti-curriculum')\n",
    "]\n",
    "\n",
    "file_exists_and_not_empty = os.path.exists(ppo_path) and os.path.getsize(ppo_path) > 0\n",
    "\n",
    "with open(ppo_path, 'a') as f:\n",
    "    if not file_exists_and_not_empty:\n",
    "        f.write(f\"{','.join(COLUMNS)}\\n\")\n",
    "        f.flush()\n",
    "    for agent in tqdm(agents):\n",
    "        print(f\"Training of '{agent.metadata['agent_name']}' via CL method '{agent.metadata['curriculum_name']}' has started\")\n",
    "        curriculum = experiments.get_curriculum(agent)\n",
    "        boxing.train_evaluate(agent, curriculum)\n",
    "        agent_df = data_frame_from_agent(agent)\n",
    "        if f.tell() == 0:\n",
    "            agent_df.to_csv(f, index=False)\n",
    "        else:\n",
    "            agent_df.to_csv(f, header=False, index=False)\n",
    "        f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aclarel_3.11.3",
   "language": "python",
   "name": "aclarel_3.11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
