{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca45a75-f165-4ea3-bc90-82975e6a1ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danorel/Workspace/Education/University/KMA/Research/aclarel\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39deedfb-bba0-4411-ba29-682770bd9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import environments.atari_games.boxing.environment as boxing\n",
    "import environments.atari_games.boxing.experiments as experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578746b-32c2-4d99-97c1-ddb34ac23df5",
   "metadata": {},
   "source": [
    "## Curriculum Learning: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe9e13-c218-4b3b-a556-4cadca967a73",
   "metadata": {},
   "source": [
    "### Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da28ed2-c431-4eaf-8c1b-06379ed1223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_frame_from_agents(agents):\n",
    "    df = pd.DataFrame()\n",
    "    for agent in agents:\n",
    "        df = pd.concat([df, agent.measurements])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177b7c8-d10a-4258-976e-b39bcf5e148b",
   "metadata": {},
   "source": [
    "## Reinforcement Learning: Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e36bc6a-1ea4-4cec-b410-2a53cee6dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = pathlib.Path(\"datasets\") / \"atari_games\" / \"boxing\"\n",
    "DATASETS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab04375-6ae4-4a04-a7ce-095a0e7c8d4a",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a7c7c-63be-44ec-ac45-8562ec58e8ba",
   "metadata": {},
   "source": [
    "#### Curriculum parameter: frame skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bae37-cc5f-4a67-90e4-0985d5940885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Autocast gradients: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                            | 0/11 [00:00<?, ?it/s]\u001b[A/Users/danorel/miniconda3/envs/aclarel_3.11.3/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/Users/danorel/Workspace/Education/University/KMA/Research/aclarel/environments/atari_games/boxing/rl_methods/__init__.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.measurements = pd.concat([self.measurements, measurement], ignore_index=True)\n",
      "\n",
      "  9%|████▋                                               | 1/11 [00:07<01:19,  7.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 0:\n",
      "\tTraining Frameskip: 4\n",
      " \tTraining Stability: 0.0\n",
      " \tAAR: -0.011\n",
      " \tSES: 0\n",
      " \tMean Reward: 5.0\n",
      " \tStd Reward: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█████████▍                                          | 2/11 [01:06<05:40, 37.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 1:\n",
      "\tTraining Frameskip: 4\n",
      " \tTraining Stability: 0.0\n",
      " \tAAR: 0.039\n",
      " \tSES: 0\n",
      " \tMean Reward: 15.0\n",
      " \tStd Reward: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██████████████▏                                     | 3/11 [02:14<06:51, 51.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 2:\n",
      "\tTraining Frameskip: 4\n",
      " \tTraining Stability: 0.0\n",
      " \tAAR: -0.011\n",
      " \tSES: 0\n",
      " \tMean Reward: 6.0\n",
      " \tStd Reward: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from environments.atari_games.boxing.rl_methods.ppo import PPOAgent\n",
    "\n",
    "ppo_agent = functools.partial(experiments.get_agent, agent_name='ppo')\n",
    "\n",
    "agents = [\n",
    "    ppo_agent(curriculum_name='baseline'),\n",
    "]\n",
    "\n",
    "for agent in tqdm(agents):\n",
    "    curriculum = experiments.get_curriculum(agent)\n",
    "    boxing.train_evaluate(agent, curriculum)\n",
    "\n",
    "ppo_df = data_frame_from_agents(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4ad78-e735-456b-9620-b119a486bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_df.to_csv(DATASETS_DIR / 'ppo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6e92a-49c0-4c9f-9ca9-2dfad2290c98",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381359f6-ce78-48fc-b4b4-450891ecf863",
   "metadata": {},
   "source": [
    "#### Curriculum parameter: frame skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c9f1e-b0ac-4375-878f-4a6eff425452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from environments.atari_games.boxing.rl_methods.dqn import DQNAgent\n",
    "\n",
    "dqn_agent = functools.partial(experiments.get_agent, agent_name='dqn')\n",
    "\n",
    "agents = [\n",
    "    dqn_agent(curriculum_name='baseline'),\n",
    "]\n",
    "\n",
    "for agent in tqdm(agents):\n",
    "    curriculum = experiments.get_curriculum(agent)\n",
    "    cart_pole.train_evaluate(agent, curriculum)\n",
    "\n",
    "dqn_df = data_frame_from_agents(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2cf0a-776a-4c0f-b564-82e866fdbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_df.to_csv(DATASETS_DIR / 'dqn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aclarel_3.11.3",
   "language": "python",
   "name": "aclarel_3.11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
